{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c33df465-2983-4503-b1b1-e87c011e6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pymupdf\n",
    "import fitz\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import io\n",
    "import re\n",
    "import unicodedata\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9f1acf-2881-4bf4-88ec-1717b44a65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a210cc-c7f7-4b1e-87a2-e1e90d2f7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a single document to database\n",
    "#add a batch of documents to database\n",
    "#retrieve name of documents in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b9b3bb-ff29-42df-8f58-4a50603aea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,       # Try 500–1000 for LLM input\n",
    "    chunk_overlap=200,     # Adds context to each chunk\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "vector_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "220a7f92-5c5c-4f7f-bf27-edd08c746f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_dir = 'documents/'\n",
    "document_title = 'lamarsh_baratta-introduction_to_nuclear_engineering_textbook_3rd_edition.pdf'\n",
    "#document_title = 'Nuclear Energy - R.Murray (2000).pdf'\n",
    "test_doc = os.path.join(document_dir, document_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "566d058d-172a-4f16-8216-bbc4615b0dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 extract text\n",
    "text_list = []\n",
    "pix_list = []\n",
    "\n",
    "with fitz.open(test_doc) as doc:\n",
    "    metadata =  doc.metadata\n",
    "    \n",
    "    for page in doc:\n",
    "        text_list.append(page.get_text())\n",
    "        #pix_list.append(page.get_pixmap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aab49c20-4748-45d2-886f-13fc66e4ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pdf_text(raw_text):\n",
    "    text = raw_text\n",
    "\n",
    "    # 1. Normalize Unicode characters (e.g., accented letters to canonical form)\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "\n",
    "    # 2. Replace common misencoded ligatures, symbols, and PDF artifacts\n",
    "    replacements = {\n",
    "        \"ﬁ\": \"fi\", \"ﬂ\": \"fl\", \"ﬀ\": \"ff\", \"ﬃ\": \"ffi\", \"ﬄ\": \"ffl\",\n",
    "        \"“\": '\"', \"”\": '\"', \"‘\": \"'\", \"’\": \"'\",\n",
    "        \"—\": \"-\", \"–\": \"-\", \"•\": \"*\",\n",
    "        \"…\": \"...\", \"±\": \"+/-\",\n",
    "        \"µ\": \"micro\",\n",
    "        \"′\": \"'\", \"″\": '\"',\n",
    "        \"fJ\": \"β\", \"y\": \"γ\", \"l0\": \"10\",\n",
    "        \"\\u00A0\": \" \",  # Non-breaking space\n",
    "    }\n",
    "    for k, v in replacements.items():\n",
    "        text = text.replace(k, v)\n",
    "\n",
    "    # 3. Remove control characters and invisible junk\n",
    "    text = re.sub(r\"[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]\", \"\", text)\n",
    "\n",
    "    # 4. Fix broken words split across lines (hyphen + newline)\n",
    "    text = re.sub(r'\\xad\\n', '', text)    # Soft hyphen + newline\n",
    "    text = re.sub(r'-\\n', '', text)       # Regular hyphen + newline\n",
    "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)  # Single newlines → space\n",
    "\n",
    "    # 5. Collapse multiple spaces and tabs\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    # 6. Collapse multiple newlines (paragraph breaks)\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)\n",
    "\n",
    "    # 7. Remove page numbers (common pattern: digits alone on a line)\n",
    "    text = re.sub(r'^\\s*\\d+\\s*$', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # 8. Remove header/footer repeated lines (if detected)\n",
    "    lines = text.splitlines()\n",
    "    if len(lines) > 2:\n",
    "        # Naive dedupe of lines that appear too often\n",
    "        from collections import Counter\n",
    "        line_counts = Counter(lines)\n",
    "        text = \"\\n\".join(\n",
    "            line for line in lines if line_counts[line] < len(lines) * 0.5\n",
    "        )\n",
    "\n",
    "    # 9. Strip leading/trailing spaces on each line\n",
    "    text = \"\\n\".join(line.strip() for line in text.splitlines())\n",
    "\n",
    "    # 10. Final cleanup: remove extra blank lines at start/end\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303d3342-ce44-41b3-b677-8ff8e18bafcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# clean text\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtext_list\u001b[49m[\u001b[32m105\u001b[39m]\n\u001b[32m      3\u001b[39m cleaned_text = clean_pdf_text(text_list[\u001b[32m105\u001b[39m])\n\u001b[32m      4\u001b[39m cleaned_text\n",
      "\u001b[31mNameError\u001b[39m: name 'text_list' is not defined"
     ]
    }
   ],
   "source": [
    "# clean text\n",
    "text_list[105]\n",
    "cleaned_text = clean_pdf_text(text_list[105])\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "29178631-b39c-4c43-837c-81117f2df03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunk text by page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8dd161e-a97f-448d-afbe-e4651d57e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dictionary of chunks\n",
    "def save_vectors(text_list, document_title, folder_path):\n",
    "    vector_library = os.path.join(folder_path, \"library.pkl\")\n",
    "    \n",
    "    if os.path.exists(vector_library):\n",
    "        with open(vector_library, \"rb\") as f:\n",
    "            existing_library = pickle.load(f)\n",
    "\n",
    "    else:\n",
    "        existing_library = []\n",
    "\n",
    "    existing_text = [entry['text'] for entry in existing_library]\n",
    "\n",
    "    book = []\n",
    "    chunk_count = 0\n",
    "\n",
    "    for i, page in enumerate(text_list):  \n",
    "        cleaned_page = clean_pdf_text(page)\n",
    "        page_chunks = text_splitter.split_text(cleaned_page)  \n",
    "    \n",
    "        for j, chunk in enumerate(page_chunks):\n",
    "        \n",
    "            if chunk in existing_text:\n",
    "                continue\n",
    "        \n",
    "            chunk_count += 1\n",
    "            vector = vector_model.encode(chunk)\n",
    "        \n",
    "            entry = {\n",
    "                \"title\" : document_title,\n",
    "                \"chunk_number\" : chunk_count,\n",
    "                \"page\" : i,\n",
    "                \"text\" : chunk,\n",
    "                \"vector\" : vector\n",
    "            }\n",
    "\n",
    "            book.append(entry)\n",
    "\n",
    "    updated_library = existing_library + book\n",
    "\n",
    "    with open(vector_library, \"wb\") as f:\n",
    "        pickle.dump(updated_library, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee93401e-aa6c-4e6f-afa7-c810ff95d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_titles(library):\n",
    "    unique_titles = list(set(item['title'] for item in library))\n",
    "    return unique_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aef41d73-db98-4e83-a52d-bf311881e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pdf(pdf_path):\n",
    "    text_list = []\n",
    "\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "    \n",
    "        for page in doc:\n",
    "            text_list.append(page.get_text())\n",
    "\n",
    "    document_title = os.path.basename(pdf_path)\n",
    "    save_vectors(text_list, document_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d390274c-566a-4e72-8f91-edb19b089ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_set(folder_path):\n",
    "    \n",
    "    for document_title in os.listdir(folder_path):\n",
    "        document_path = os.path.join(folder_path, document_title)\n",
    "\n",
    "        text_list = []\n",
    "        \n",
    "        with fitz.open(document_path) as doc:\n",
    "\n",
    "            for page in doc:\n",
    "                text_list.append(page.get_text())\n",
    "\n",
    "        save_vectors(text_list, document_title, folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "564a37f6-00c3-4bc6-8c29-6aa7c8fecc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_set('documents/unstructured/world_of_warcraft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9876950-8716-456a-81c0-0bd82c9c8fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documents/unstructured/world_of_warcraft/library.pkl\", \"rb\") as f:\n",
    "    library = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82acb2c4-0159-4071-9338-b17e6d6145f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['World of Warcraft 2nd Edition.pdf']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_titles(library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac25e9df-8c24-4964-9d08-29025937def7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2185"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b87623-e61f-48fa-81af-c3034d0e42ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
